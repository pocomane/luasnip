--[===[DOC

= pegcore

-- TODO : CLEAN UP ! -- THIS IS A DRAFT ! --
-- TODO : ADD comment in grammar ?
-- TODO : SYNC : doc and pegcore api
-- TODO : SYNC : doc and matchHandlerFunc api
-- TODO - FIX THE MATCH HANDLER !

[source,lua]
----
function pegcore( grammarStr, matchHandlerFunc ) -> parserFunc
function parserFunc( inputStr, positionInt ) -> sizeInt, astTab
----

This is a module to write parser though PEG.

A parser is a `parserFunc` function that works on the `inputStr` string and
returns nil if the string does not match a specific pattern. If it does, the
parser returns the `sizeInt` number. It represents the size of a substring
starting at beginning of `inputStr`. This substring does match the pattern.

The `grammarStr` string describes the parser and so the pattern that it try to
match. The syntax and PEG sematic is desripted in the next character.

The `positionInt` integer is the position inside the input string where to start
to try the match.

The `astTab` table is a table representition of how the string was matched. It
is nil if the parser does not match. Otherwise it will contain recursively a
sub table for each basic pattern or rules that matched. The table generated by
a basic (or lua) pattern, contains the matched string. The sub-table
corresponding to a non-terminal rule will contain also a "tag" field with the
name of the non-terminal.

The `matchHandlerFunc` will be called each time a non-terminal matches. The
matched sub-table is passed to it, the same one that can be found in the
`astTab`. If it retusns nil, the parser will be considered to not match.
Otherwise, the result will be substitute to the sub-table inside the resulting
`astTab`, and the parser will be considered to match (as if no
`matchHandlerFunc` was provided)

== PEG basic

The returning `sizeInt` can be interpreted as the number of the character that
the parser "Consumes", if it matches. This analogy is usefull when reasoning on
composed pattern that can consume different part of the input (continue reading
for more details)

The `grammarStr` string describes the parser and so the pattern that it try to
match. The basic pattern strings are like `toplevel<-'%\XX'` where XX are two
hex digits. These parsers returns 1 if the first character of the `inputStr` is
exactly the character represented by the XX number. If the characeter to mach
is not a digit ar a letter or a whitespace, it can be used directly, e.g. `' '`
is the same of `'\20'`.  A ' and a \ can be matched with `'%\27'` and `'%\5C'`.

All the other parser can be obtained by the previous one, using the composition
mechanisms described in the next section.

== Composition mechanisms

A name can be assigned to a specific pattern to reuse it in other part of PEG.
We refert to this with "Non-terminal" or "Peg rule". The syntax is `x<-'a'
toplevel<-x` where `x` is the name assigned to the pattern `'a'`. Recursive
definition are allowed, but be aware that this can arise infinte-loop issues.
The full set of defined non-terminal can be seen as a set of rules defining a
parser and so a language.

The `toplevel` keyword used before is just an ordinay non-terminal definition.
The only special thing about `toplevel` is that it is the root non-terminal
that `parserFunc` will try to match. So a `toplevel` terminal must be defined,
otherwise `pegcore` will return nil.

The non-terminal name can be composed of letters, digits and underscore, and
they are case sensitive.  Such name will represent a previously defined
non-terminal in the following. However the following is valid also substituding
a basic parser to such names, as well as a sub-expression.

The subexpression `( ... )` can contain any basic parser, or other
sub-expression, or non-terminals, or one of the other composition operations.
It is used to group operations togeter and fix their the precedence order.

The not predicate `toplevel<-!x` will fail if `x` matches. Otherwise it will
match an empty strings. So it does never consumes anything in the string.

The parser sequence `toplevel<-x,y` will match if `x` matches and if `y`
matches starting where `x` stopped. It return the sum of the result of `x` and
`y`. This is where the "Consumption" analogy helps. for example when the parser
`toplevel<-'a','b'` is applied to the string "abcd", "a" will be matched from
the left part of the sequence consuming one character. So the right part of the
sequence will be applied to the "bcd" sub-string, and will match returning 1.
The whole sequence will match the string returning 2. Other item can be added
to the sequence, e.g. `toplevel<-a,b,c,d`.

The parser alternation `toplevel<-x/y` will try to match `x`. If it mathes then
its result will be returned by the whole alternation. Otherwise it will try to
match `y`. More than two alternation can be given, e.g. `toplevel<-w/x/y/z`. If
none of the alternatve match, the wole alternation will fail.

== Extended basic patterns

Every parser can be composed from the basic ones with the shown mchanism,
however some other parser and operation are defined by default in `pegcore` to
make easier to write grammars.

The basic parser sequence `'abc'` is the same of `('a','b','c')`; escapes can
be used as usual, e.g. `'a\20b'`

Lua pattern parser can be used in the parser sequence, e.g. `'a%wb'`. So,
actually anything between two ' is interepreted as a lua pattern, after the `\XX`
sequence expansion. This can be used instead of common PEG extensions, e.g. the
any character parser `'.'` or the character sets like `'[a-zA-Z]'`.

The empty `~` pattern is the same of `((!'a')/(!!'a'))`. It always matches
the empty string i.e. it always returns 0. [1]

The optional pattern `a?` is the same of `(a/~)`. It matches `a` otherwise it
match the empty string.

The zero-or-more pattern `a*` is the same of `R<-a toplevel<-a,(R/~)`. It
continues to match `a` until it fails. Then it retuns the whole matche. If `a`
never matches, `a*` matches the empty strings.

The one-or-more pattern `a+` is the same of `a+`. It behaves like `a*` except
it fails if `a` never matches.

The check-and-backtrack pattern `&a` is the same of `(!(!(a)))`. It mathces the
empty string if a matches, otherwise it failse. It is similar to `a` but it
never consumes the input.

[1] Note an interesting sub-class of PEG is the one without the Not rule but
    with Empty defined as a basic parser. These kind of PEG expression can
    construct any parser that a fully featured PEG can construct, with the
    following exception: if a parser match the empty string, it will match any
    string.

== Whole Peg grammar

The grammar of `grammarStr` is actually more flexible of the one described till
now. For example you can use spaces and newlines to format it. The whole
grammar, written itself with PEG, is the following:

```
toplevel <- rule*
rule <- identifier, ws, '<-', alternation, ws
alternation <- sequence, (ws, '/', sequence)*
sequence <- (ws, '[!&]'?, suffix)+
suffix <- primary, ws, '[*+?]'
primary <- expression / pattern / empty / (identifier, !'<-')
expression <- ws, '(', alternation, ws, ')'
pattern <- ws, '%\27', (!'%\27', '.')*, '%\27'
empty <- ws, '~'
identifier <- ws, '[a-zA-Z]', '[_0-9a-zA-Z]'+
ws <- '[ \0D\10\09]'
```

== Result analisys considerations

To analize the match, you can either parse the `astTab` or use a
`matchHandlerFunc`. However, usually, the former method has better performance
since the elaboration is performed only on the final result, while
`matchHandlerFunc` is called also on partial results that could be discarded in
a second time (due to non-matching super-rule). So we suggest to use that one.
The `matchHandlerFunc` is more usefull for adding some special parsing
condition thar are simpler to write in lua instead of PEG (or maybe to write
some small parser part that can not be even written with the sole PEG).

The `pegcore` parser itself is written using the same engine used to generate
the final parser. So `pegcore` also needs to analize the match results. To this
purpose it uses the `matchHandlerFunc` method because it is simpler, and
because the PEG rules are usually small. This method will not impact on the
performance of the resulting parser, only on the ones of the PEG expression
parser.

== Example

[source,lua,example]
----
local pegcore = require 'pegcore'

local grammar = [[
whitespace <- '[ \t]*'
name <- '[a-z]+'
toplevel <- whitespace, name, ( whitespace, ',', whitespace, name ) *
]]

local _, list_parse = pegcore(grammar)
local p, ast = list_parse.func 'horse, cat, duck, shark'

assert( ast[2].tag == 'name' )
assert( ast[2][1] == 'horse' )

assert( ast[3][1][4].tag == 'name' )
assert( ast[3][1][4][1] == 'cat' )

assert( ast[3][2][4].tag == 'name' )
assert( ast[3][2][4][1] == 'duck' )

assert( ast[3][3][4].tag == 'name' )
assert( ast[3][3][4][1] == 'shark' )

-- TODO - FIX THE MATCH HANDLER !

-- local result = {}
-- local function handle( m )
--   print(require'valueprint'(m))
--   if m.tag == 'name' then
--     result[1+#result] = m[1]
--   end
--   print('done')
-- end

-- local _, list_parse = pegcore(grammar, handle)
-- list_parse.func('horse, cat, duck, shark')

-- assert( result[1] == 'horse' )
-- assert( result[2] == 'cat' )
-- assert( result[3] == 'duck' )
-- assert( result[4] == 'shark' )

----

]===]

-- TODO : remove 'ast' generation form the core !

-- TODO : CLEAN UP ! -- THIS IS A DRAFT ! --

local deb_verbose = false
LOG = function(...)
  if not deb_verbose then return end
  io.write("#")
  local vp = require'valueprint'
  for k = 1, select('#',...) do
    local s = select(k, ...)
    io.write(" ",vp(s):gsub('\n','\n# '),'')
  end
  io.write("\n")
end

local function peg_pattern_matcher( pattern )
  pattern = '^(' .. pattern .. ')'
  result = function( DATA, CURR )
    LOG('trying pattern ', pattern, ' at',DATA:sub(CURR or 1),'...')
    CURR = CURR or 1
    local d = DATA:sub( CURR )
    local ast = { d:match( pattern ) }
    if #ast == 0 then
      return nil, nil
    end
    local size = #(ast[1])
    return size, ast
  end

  return result
end

local function peg_alternation( alternatives )
  local np = #alternatives
  for p = 1, np do local P = alternatives[p] end
  return function( DATA, CURR )
    LOG('trying alternation at',DATA:sub(CURR or 1),'...')
    for p = 1, np do
      local X, r = alternatives[p]( DATA, CURR )
      if nil ~= r then
        r = { r, tag = "a"..tostring(p), selected = p }
        return X, r
      end
    end
    return nil, nil
  end
end

local function peg_sequence( sequence )
  local np = #sequence
  for p = 1, np do local P = sequence[p] end
  return function( DATA, CURR )
    LOG('trying sequence at',DATA:sub(CURR or 1),'...')
    CURR = CURR or 1
    local OLD, ast = CURR, { tag = "s" }
    for p = 1, np do
      local X, r = sequence[p]( DATA, CURR )
      if nil == r then
        return nil, nil
      end
      CURR = CURR + X
      ast[1+#ast] = r
    end
    return CURR-OLD, ast
  end
end

local function peg_not( child_parser )
  return function( DATA, CURR )
    LOG('trying not-operator at',DATA:sub(CURR or 1),'...')
    local ast = { tag = "n" }
    local X, r = child_parser( DATA, CURR )
    if nil == r then
      return 0, ast
    end
    return nil, nil
  end
end

local function peg_empty()
  return function( DATA, CURR)
    LOG('trying empty at',DATA:sub(CURR or 1),'...')
    local ast = { tag = "e" }
    return 0, ast
  end
end

local function peg_zero_or_more( child_parser )
--   local rec
--   local function REC(...) return rec(...) end
--   rec = peg_alternation({peg_sequence({x,REC}),peg_empty()})
--   return rec
  return function( DATA, CURR )
    LOG('trying zero-or-more at',DATA:sub(CURR or 1),'...')
    CURR = CURR or 1
    local OLD, ast = CURR, { tag = "z" }
    while true do
      local X, r = child_parser( DATA, CURR )
      if nil == r then break end
      CURR = CURR + X
      ast[1+#ast] = r
    end
    return CURR-OLD, ast
  end
end

-- usability wrappers
local parser_wrapper_mt
local function peg_operator_wrap(op)
  if not parser_wrapper_mt then
    local function geti(t, k)
      if k == 'PEG' then
        if rawget(t, 1) then error('parser alread have a PEG expression set', 3) end
        return 1
      elseif k == 'EXT' then
        if rawget(t, 2) then error('parser alread have an exteral handler set', 3) end
        return 2
      else
        error('unsupported PEG field "'..tostring(k)..'"', 3)
      end
    end
    parser_wrapper_mt = {
      __call = function(t, d, ...)
        local s1 = rawget(t, 1)
        local s2 = rawget(t, 2)
        if s2 then
          return s2(d, s1(d, ...))
        else
          return s1(d, ...)
        end
      end,
    __index = function(t, k) return rawget(t, geti(t, k)) end,
    __newindex = function(t, k, v) return rawset(t, geti(t, k), v) end,
    }
  end
  if op then
    return function(...)
      return setmetatable({op(...), false}, parser_wrapper_mt)
    end
  else
    return function(...)
      return setmetatable({false, false}, parser_wrapper_mt)
    end
  end
end

-- TODO : RETURN THIS !
local _M = {
  ZER = peg_operator_wrap(peg_zero_or_more),
  EMP = peg_operator_wrap(peg_empty),
  NOT = peg_operator_wrap(peg_not),
  SEQ = peg_operator_wrap(peg_sequence),
  ALT = peg_operator_wrap(peg_alternation),
  PAT = peg_operator_wrap(peg_pattern_matcher),
  REC = peg_operator_wrap(),
}

--------------------------------------------------------7
-- TODO : move somewhere else ! (maybe remove ?)

local function create_core_parser( match_handler )
  local EMP, PAT, ALT, SEQ = _M.EMP, _M.PAT, _M.ALT, _M.SEQ
  local NOT, ZER, REC = _M.NOT, _M.ZER, _M.REC

  local whitespace =   PAT'[ \t\n\r]*'

  local identifier =   SEQ{ whitespace, PAT'[a-zA-Z][_0-9a-zA-Z]*', }
  local pattern =      SEQ{ whitespace, PAT"'[^']*'", }
  local empty =        SEQ{ whitespace, PAT'~', }
  local alternation =  REC()
  local expression =   SEQ{ whitespace, PAT'%(', alternation, whitespace, PAT'%)', }
  local capture =      SEQ{ PAT':', identifier, }

  local primary =      ALT{  expression, pattern, empty, capture, identifier, NOT( PAT'<%-' ), } -- TODO : !<- should be in a sequence

  local suffix =       SEQ{ primary, whitespace, PAT'[*+?]?', }
  local prefix =       SEQ{ whitespace, PAT'[&!]?', suffix, }

  local sequence =     REC()
  sequence.PEG =       SEQ{ prefix,   ZER( SEQ{ whitespace, PAT',', sequence, }), }
  alternation.PEG =    SEQ{ sequence, ZER( SEQ{ whitespace, PAT'/', alternation, }), }

  local rule =         SEQ{ identifier, whitespace, PAT'<%-', alternation, whitespace, }
  local toplevel =     ZER( rule )

  local parsed_grammar = {} -- parsed rules
  local captured_grammar = {}

  -- TODO : capture-group experimetatuon - SIMPLIFY !!! !
  local parsed_ref = function( rule, return_cather )
    local capture = captured_grammar[rule]
    if not capture then
      capture = {}
      captured_grammar[rule] = capture
    end

    local function define( data, curr )
      LOG('trying non-terminal', rule, 'at',data:sub(curr or 1),'...')
      local p
      if 'function' == type(parsed_grammar) then
        p = parsed_grammar(rule)
      else
        p = parsed_grammar[rule]
      end
      local a,b = p( data, curr )
      if b then b.tag = rule end
      if b and rule_handler then
        b = rule_handler( b )
        -- TODO : do not match if b == nil !!?
      end

      if a ~= nil then
        curr = curr or 1
        capture[1] = curr
        capture[2] = curr + a -1
      end

      return a,b
    end

    local function refer( DATA, CURR )
      CURR = CURR or 1
      LOG('trying captured at', DATA:sub(CURR), '...')
      local cap = capture
      if not capture[1] then return EMP()( DATA, CURR ) end
      cap = DATA:sub( capture[1], capture[2] )
      local siz = #cap
      local cur = DATA:sub( CURR, CURR + siz -1 )
      if cap ~= cur then return nil, nil end
      return siz, { cap, tag = 'c', }
    end

    if not return_cather then return define end
    return define, refer
  end

  identifier.EXT = function(d, c, x)
    if c and c >= 0 then
      local name = x[2][1]
      x.func = parsed_ref( name )
    end
    return c, x
  end

  pattern.EXT = function(d, c, x)
    if c and c >= 0 then
      local y = x
      y = y[2][1]:sub( 2, -2 ):gsub( '\\%x%x', function( h )
        return string.char(tonumber( h:sub( 2 ), 16 ))
      end)
      x.func = PAT( y )
    end
    return c, x
  end

  empty.EXT = function(d, c, x)
    if c and c >= 0 then
      x.func = EMP()
    end
    return c, x
  end

  expression.EXT = function(d, c, x)
    if c and c >= 0 then
      x.func = x[3].func
    end
    return c, x
  end

  capture.EXT = function(d, c, x)
    if c and c >= 0 then
      local _, f = parsed_ref( x[2][2][1], true )
      x.func = f
    end
    return c, x
  end

  primary.EXT = function(d, c, x)
    if c and c >= 0 then
      x.func = x[1].func
    end
    return c, x
  end

  suffix.EXT = function(d, c, x)
    if c and c >= 0 then
      local o = x[3][1]
      if     o == '*' then x.func = ZER( x[1].func )
      elseif o == '?' then x.func = ALT{ x[1].func, EMP() }
      elseif o == ''  then x.func = x[1].func
      elseif o == '+' then x.func = function(...)
          local y, z = (SEQ{ x[1].func, ZER( x[1].func ) })(...)
          if not z then return y, z end
          local w = {}
          w.tag = 'o'
          w[1] = z[1]
          for _, k in ipairs(z[2]) do
            w[1+#w] = k
          end
          return y, w
        end
      end
    end
    return c, x
  end

  prefix.EXT = function(d, c, x)
    if c and c >= 0 then
      local o = x[2][1]
      if     o == '!' then x.func = NOT( x[3].func )
      elseif o == '&' then x.func = NOT( NOT( x[3].func ))
      elseif o == ''  then x.func = x[3].func
      end
    end
    return c, x
  end

  sequence.EXT = function(d, c, x)
    if c and c >= 0 then
      if 0 == #(x[2]) then
        x.func = x[1].func
        return c, x
      end
      local seqa = x[1].seq
      if not seqa then seqa = { x[1].func } end
      local seqb = x[2][1][3].seq
      if not seqb then seqb = { x[2][1][3].func } end
      local seq = {}
      for _, v in ipairs(seqa) do seq[1+#seq] = v end
      for _, v in ipairs(seqb) do seq[1+#seq] = v end
      x.seq = seq
      x.func = SEQ(seq)
    end
    return c, x
  end

  alternation.EXT = function(d, c, x)
    if c and c >= 0 then
      if 0 == #(x[2]) then
        x.func = x[1].func
        return c, x
      end
      local alta = x[1].alt
      if not alta then alta = { x[1].func } end
      local altb = x[2][1][3].alt
      if not altb then altb = { x[2][1][3].func } end
      local alt = {}
      for _, v in ipairs(alta) do alt[1+#alt] = v end
      for _, v in ipairs(altb) do alt[1+#alt] = v end
      x.alt = alt
      x.func = ALT(alt)
    end
    return c, x
  end

  rule.EXT = function(d, c, x)
    if c and c >= 0 then
      local tag = x[1][2][1]
      local func = x[4].func
      parsed_grammar[tag] = func
    end
    return c, x
  end

  toplevel.EXT = function(d, c, x)
    if c and c >= 0 then
      x.func = parsed_grammar.toplevel and parsed_ref'toplevel'
    end
    return c, x
  end

  return toplevel
end

local function pegcore( peg_rules, rule_handler )
  -- NOTE : here the compiler is implemente as a matching-time handler.
  local meta_parser = create_core_parser( rule_handler )
  return meta_parser( peg_rules, 1 )
end

return pegcore
